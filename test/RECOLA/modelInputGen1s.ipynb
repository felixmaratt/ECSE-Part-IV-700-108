{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import librosa as lbr\r\n",
    "from pydub import AudioSegment, silence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def silenceStampExtract(audioPath, length):\r\n",
    "    myaudio = AudioSegment.from_wav(audioPath)\r\n",
    "    slc = silence.detect_silence(myaudio, min_silence_len=1000, silence_thresh=-32)\r\n",
    "    slc = [((start/1000),(stop/1000)) for start,stop in slc] # convert to sec\r\n",
    "    slc = np.array([item for sublist in slc for item in sublist]) # flatten\r\n",
    "    slc = np.around(slc, 0) # whole number\r\n",
    "    # Tag filling\r\n",
    "    tagList = list()\r\n",
    "    slc = np.append(slc, 9999) # use length to determine the end\r\n",
    "    time = 0\r\n",
    "    idx = 0\r\n",
    "    if slc[0] == 0:\r\n",
    "        # filling start with Stag = 'S'\r\n",
    "        tag = 'S'\r\n",
    "        idx += 1\r\n",
    "    else:\r\n",
    "        # filling start with Stag = 'V'\r\n",
    "        tag = 'V'\r\n",
    "    for i in range(length):\r\n",
    "        if time >= slc[idx]:\r\n",
    "            idx += 1\r\n",
    "            tag = 'V' if (idx % 2 == 0) else 'S'\r\n",
    "        else:\r\n",
    "            pass\r\n",
    "        tagList.append(tag)\r\n",
    "        time += 1\r\n",
    "    return pd.DataFrame(tagList, columns=['voiceTag'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def vaAvg(df, VA):\r\n",
    "    df['Time'] = df['time']\r\n",
    "    df[VA] = df.iloc[:, 1:-1].sum(axis=1)/6\r\n",
    "    return df[['Time', VA]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def oneSecondVa(df, VA):\r\n",
    "    df = vaAvg(df, VA)\r\n",
    "    vaDf = df[0:0]\r\n",
    "    rowCount = 0 # used for averaging, count the number of rows in a second\r\n",
    "    currentVA = 0\r\n",
    "    for row in df.itertuples(index=False):\r\n",
    "        if (row.Time == int(row.Time) and rowCount != 0):\r\n",
    "            vaDf.loc[vaDf.shape[0]] = [int(row.Time) - 1, currentVA / rowCount]\r\n",
    "            rowCount = 0\r\n",
    "            currentVA = 0\r\n",
    "        currentVA = currentVA + row[1]\r\n",
    "        rowCount = rowCount + 1\r\n",
    "\r\n",
    "    vaDf.loc[vaDf.shape[0]] = [int(row.Time) - 1, currentVA / rowCount]\r\n",
    "\r\n",
    "    return vaDf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def featureExtract(audioFile):\r\n",
    "    # parameters of 1s window under 44.1kHZ\r\n",
    "    samplingRate = 44100\r\n",
    "    frameLength = 44100\r\n",
    "    mfccNum = 5\r\n",
    "\r\n",
    "    x, sr = lbr.load(audioFile, sr=samplingRate, mono=True)\r\n",
    "    frames = range(len(x)//frameLength+1)\r\n",
    "    t = lbr.frames_to_time(frames, sr=sr, hop_length=frameLength)\r\n",
    "\r\n",
    "    ##################Energy##################\r\n",
    "    rms = ((lbr.feature.rms(x, frame_length=frameLength, hop_length=frameLength, center=True))[0])\r\n",
    "    rms = 20*np.log10(rms)\r\n",
    "\r\n",
    "    ##################F0##################\r\n",
    "    f0Result = lbr.yin(x, 50, 300, sr, frame_length=frameLength*4)\r\n",
    "\r\n",
    "    ##################MFCC##################\r\n",
    "    # Transpose mfccResult matrix\r\n",
    "    mfccResult = lbr.feature.mfcc(x, sr=sr, n_mfcc=mfccNum, hop_length=frameLength).T\r\n",
    "\r\n",
    "    ########################################\r\n",
    "    dfT = pd.DataFrame(t, columns=['Time'])\r\n",
    "    dfR = pd.DataFrame(rms, columns=['RMS'])\r\n",
    "    dfF = pd.DataFrame(f0Result, columns=['F0'])\r\n",
    "    \r\n",
    "    # MFCC Title \r\n",
    "    mfccTitle = list()\r\n",
    "    for num in range(mfccNum):\r\n",
    "        mfccTitle.append('MFCC'+str(num+1))\r\n",
    "    dfM = pd.DataFrame(mfccResult, columns=mfccTitle)\r\n",
    "\r\n",
    "    return dfT.join(dfR).join(dfF).join(dfM)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Main program entry\r\n",
    "def main():\r\n",
    "    inputPath = '../../inputFile/emotional_behaviour/'\r\n",
    "    outputPath = '../../inputFile/modelInput/oneSecond/'\r\n",
    "\r\n",
    "    print('Constructing dataframe')\r\n",
    "    dataDict = dict()\r\n",
    "    for dir, _, filenames in os.walk(inputPath):\r\n",
    "        for file in filenames:\r\n",
    "            keyName = file[:file.rfind('.')]\r\n",
    "            if dir.find('arousal') != -1:\r\n",
    "                currentDf = oneSecondVa(pd.read_csv(os.path.join(dir, file), sep=';'), 'Arousal')\r\n",
    "            elif dir.find('valence') != -1:\r\n",
    "                currentDf = oneSecondVa(pd.read_csv(os.path.join(dir, file), sep=';'), 'Valence')\r\n",
    "            elif dir.find('recordings') != -1:\r\n",
    "                currentDf = featureExtract(os.path.join(dir, file))\r\n",
    "                tagDf = silenceStampExtract(os.path.join(dir, file), currentDf.shape[0])\r\n",
    "                currentDf = currentDf.join(tagDf)\r\n",
    "            else:\r\n",
    "                continue\r\n",
    "\r\n",
    "            if keyName in dataDict:\r\n",
    "                dataDict[keyName] = dataDict[keyName].join(currentDf.drop(['Time'], axis=1))\r\n",
    "            else:\r\n",
    "                dataDict[keyName] = currentDf\r\n",
    "\r\n",
    "    print('Saving dataframe to output path')\r\n",
    "    for key in dataDict:\r\n",
    "        valence = dataDict[key].pop('Valence')\r\n",
    "        dataDict[key].insert(1, valence.name, valence)\r\n",
    "        dataDict[key].to_csv(outputPath+'reco00'+key[1:]+'pp.csv', index=False)\r\n",
    "    \r\n",
    "    print('Tasks are completed')\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    main()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit"
  },
  "interpreter": {
   "hash": "f7291e4b392a32fbfa525b87d1bbd0a3d888adf3d0deca0c205c61b9e7284b82"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}